{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fetch the dataset ####\n",
    "categories = ['comp.sys.ibm.pc.hardware','comp.graphics','comp.sys.mac.hardware','comp.os.ms-windows.misc',\n",
    "              'rec.autos', 'rec.motorcycles','rec.sport.baseball','rec.sport.hockey']\n",
    "dataset = fetch_20newsgroups(subset= 'all', categories=categories,shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=3, stop_words='english')\n",
    "X = vectorizer.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7882, 27768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "    n_clusters=2, n_init=30, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "    n_clusters=2, n_init=30, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=0, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7882,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,7882):\n",
    "    if dataset.target[x] > 3 : \n",
    "        dataset.target[x] = 1\n",
    "    else:\n",
    "        dataset.target[x] = 0\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for document 0 : 1\n",
      "Actual    label for document 0 : 0\n",
      "Predicted label for document 1 : 1\n",
      "Actual    label for document 1 : 0\n",
      "Predicted label for document 2 : 1\n",
      "Actual    label for document 2 : 0\n",
      "Predicted label for document 3 : 1\n",
      "Actual    label for document 3 : 0\n",
      "Predicted label for document 4 : 0\n",
      "Actual    label for document 4 : 1\n",
      "Predicted label for document 5 : 1\n",
      "Actual    label for document 5 : 1\n",
      "Predicted label for document 6 : 1\n",
      "Actual    label for document 6 : 0\n",
      "Predicted label for document 7 : 0\n",
      "Actual    label for document 7 : 1\n",
      "Predicted label for document 8 : 1\n",
      "Actual    label for document 8 : 0\n",
      "Predicted label for document 9 : 1\n",
      "Actual    label for document 9 : 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(\"Predicted label for document %d : %d\"%(i,X_predict[i]))\n",
    "    print(\"Actual    label for document %d : %d\"%(i,dataset.target[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Matrix:\n",
      "[[   4 3899]\n",
      " [1718 2261]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-514dea5f19b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcntg_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcntg_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Contingency matrix for r = 1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "cntg_matrix = contingency_matrix(dataset.target,X_predict )\n",
    "\n",
    "print(\"Contingency Matrix:\")\n",
    "print (cntg_matrix)\n",
    "\n",
    "plt.matshow(cntg_matrix,cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.title('Contingency matrix for r = 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(dataset.target, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(dataset.target, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(dataset.target, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, km.labels_))\n",
    "print(\"Adjusted mutual information score: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, km.labels_))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(1000, random_state=0)\n",
    "X_reduced = svd.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dimensions = np.arange(1000)\n",
    "\n",
    "exp_var = X_reduced.explained_variance_ratio_.cumsum()\n",
    "\n",
    "    \n",
    "## Now plot the # of variance against the dimensions\n",
    "plt.plot(dimensions,exp_var)\n",
    "plt.xlabel(\"Number of Dimensions\")\n",
    "plt.ylabel(\"Percentage of Explained Variance\")\n",
    "plt.show()\n",
    "print(\"Total percentage Variance for all 1000 dimension is: {}% \".format(svd.explained_variance_ratio_.sum()*100 ))\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means on Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "r = [1,2,3,5,10,20,50,100,300]\n",
    "\n",
    "#Metric buckets\n",
    "cont_matrix = []\n",
    "homogenity = []\n",
    "completeness = []\n",
    "vmeasure = [] \n",
    "adjrand = []\n",
    "adjmutualinfo = []\n",
    "\n",
    "X_SVD_reduced = svd.transform(X)\n",
    "y = dataset.target\n",
    "\n",
    "for iter in r:\n",
    "    print('Current r value sweeping = %d' %iter)\n",
    "    \n",
    "    ykm_svd = km.fit_predict(X_SVD_reduced[:,:iter])\n",
    "\n",
    "\n",
    "    mat = contingency_matrix(y,ykm_svd )\n",
    "    cont_matrix.append(mat)\n",
    "    \n",
    "\n",
    "    plt.matshow(mat,cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    plt.title('Contingency matrix for r = 1')\n",
    "    plt.show()\n",
    "    \n",
    "    homogenity.append(metrics.homogeneity_score(y, ykm_svd ))\n",
    "    completeness.append(metrics.completeness_score(y, ykm_svd ))\n",
    "    vmeasure.append(metrics.v_measure_score(y, ykm_svd ))\n",
    "    adjrand.append(metrics.adjusted_rand_score(y, ykm_svd ))\n",
    "    adjmutualinfo.append(metrics.adjusted_mutual_info_score(y, ykm_svd ))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = plt.scatter(x= r,y= homogenity,color='r',marker='x')\n",
    "plt.ylabel('Homogenity')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Homogenity Score for all r dimensions in SVD')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot the completeness score\n",
    "plt.scatter(x= r,y= completeness,color='r',marker='x')\n",
    "plt.ylabel('Completeness')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Completeness Score for all r dimensions in SVD')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot vmeasure score\n",
    "plt.scatter(x= r,y= vmeasure,color='r',marker='x')\n",
    "plt.ylabel('V-Measure')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('V-Measure Score for all r dimensions in SVD')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot rand score\n",
    "plt.scatter(x= r,y= adjrand,color='r',marker='x')\n",
    "plt.ylabel('Rand')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Rand Score for all r dimensions in SVD')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot mutual information score\n",
    "plt.scatter(x= r,y= adjmutualinfo,color='r',marker='x')\n",
    "plt.ylabel('Mutual info')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Mutual info score Score for all r dimensions in SVD')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means on NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "#Metric buckets\n",
    "cont_matrix = []\n",
    "homogenity = []\n",
    "completeness = []\n",
    "vmeasure = [] \n",
    "adjrand = []\n",
    "adjmutualinfo = []\n",
    "\n",
    "\n",
    "for iter in r:\n",
    "    print('Current r value sweeping = %d' %iter)\n",
    "# NMF dim reduction\n",
    "    nmf = NMF(n_components=iter, init='random', random_state=0)\n",
    "    X_NMF_reduced = nmf.fit_transform(X)\n",
    "\n",
    "    km2 = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "    #km.fit(X_SVD_reduced)\n",
    "    ykm_nmf = km2.fit_predict(X_NMF_reduced)\n",
    "\n",
    "   # Conf Matrix ( y= dataset.target)\n",
    "    mat = contingency_matrix(y, ykm_nmf )  \n",
    "    cont_matrix.append(mat)\n",
    "   # Plots \n",
    "    plt.matshow(mat,cmap=plt.cm.Blues)\n",
    "    plt.colorbar()\n",
    "    plt.title('Contingency matrix for r = %d' %iter)\n",
    "    plt.show()\n",
    "    #http://scikit-learn.org/stable/auto_examples/text/document_clustering.html   \n",
    "    homogenity.append(metrics.homogeneity_score(y, ykm_nmf ))\n",
    "    completeness.append(metrics.completeness_score(y, ykm_nmf ))\n",
    "    vmeasure.append(metrics.v_measure_score(y, ykm_nmf ))\n",
    "    adjrand.append(metrics.adjusted_rand_score(y, ykm_nmf ))\n",
    "    adjmutualinfo.append(metrics.adjusted_mutual_info_score(y, ykm_nmf ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot metrics\n",
    "#plot the homogenity score\n",
    "sp = plt.scatter(x= r,y= homogenity,color='r',marker='x')\n",
    "plt.ylabel('Homogenity')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Homogenity Score for all r dimensions in NMF')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot the completeness score\n",
    "plt.scatter(x= r,y= completeness,color='r',marker='x')\n",
    "plt.ylabel('Completeness')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Completeness Score for all r dimensions in NMF')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot vmeasure score\n",
    "plt.scatter(x= r,y= vmeasure,color='r',marker='x')\n",
    "plt.ylabel('V-Measure')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('V-Measure Score for all r dimensions in NMF')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot rand score\n",
    "plt.scatter(x= r,y= adjrand,color='r',marker='x')\n",
    "plt.ylabel('Rand')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Rand Score for all r dimensions in NMF')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#plot mutual information score\n",
    "plt.scatter(x= r,y= adjmutualinfo,color='r',marker='x')\n",
    "plt.ylabel('Mutual info')\n",
    "plt.xlabel('r Principal components')\n",
    "plt.title('Mutual info score Score for all r dimensions in NMF')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SVD_reduced.shape\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "\n",
    "vis_best_r = km.fit_predict(X_SVD_reduced[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code plots\n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.title('SVD Best value with clustering label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code plots\n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.title('SVD Best value with Ground Truth label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=2, init='random', random_state=0)\n",
    "X_NMF_reduced = nmf.fit_transform(X)\n",
    "\n",
    "km2 = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "#km.fit(X_SVD_reduced)\n",
    "ykm_nmf = km2.fit_predict(X_NMF_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code plots\n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = ykm_nmf)\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.title('NMF Best value with clustering label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code plots\n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.title('NMF Best value for Ground Truth label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scal_matrix = scaler.fit_transform(X_SVD_reduced[:,:2])\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(scal_matrix)\n",
    "\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Normalization with Cluster label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Normalization with Ground Truth Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post SVD \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after SVD normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD Tranformation\n",
    "svd_log_matrix = np.log1p(X_SVD_reduced[:,:2])\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(svd_log_matrix)\n",
    "\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Transformation with Cluster label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Transformation with Ground Truth Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post SVD \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after SVD normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code does log transform + Normalize\n",
    "scaler = StandardScaler()\n",
    "scal_matrix = scaler.fit_transform(svd_log_matrix)\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(scal_matrix)\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Normal. + Trans. with cluster label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Normal. + Trans. with Ground Truth label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post SVD \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after SVD normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below code does Normalize + log transform\n",
    "\n",
    "scal_matrix -= scal_matrix.min()\n",
    "svd_log_matrix = np.log1p(scal_matrix)\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(svd_log_matrix)\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Trans. + Norm. with Cluster label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(X_SVD_reduced[:,0],X_SVD_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('SVD Trans. + Norm. with Ground Truth label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post SVD \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after SVD normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization For NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scal_matrix = scaler.fit_transform(X_NMF_reduced)\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(scal_matrix)\n",
    "\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Normalization with cluster label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Normalization with Ground Truth label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post NMF \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after NMF normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_log_matrix = np.log1p(X_NMF_reduced)\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(nmf_log_matrix)\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Transformation with Cluster Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Transformation with Ground Truth Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post NMF \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after NMF normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code does log transform + Normalize\n",
    "scaler = StandardScaler()\n",
    "scal_matrix = scaler.fit_transform(nmf_log_matrix)\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(scal_matrix)\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Tranform + Normal. with Cluster Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Tranform + Normal. with Ground Truth Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post NMF \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after NMF normalization')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below code does Normalize + log transform\n",
    "\n",
    "scal_matrix -= scal_matrix.min()\n",
    "nmf_log_matrix = np.log1p(scal_matrix)\n",
    "km = KMeans(n_clusters=2, init='k-means++', max_iter=1000, random_state = 0,n_init = 30)\n",
    "vis_best_r = km.fit_predict(nmf_log_matrix)\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = vis_best_r)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Normal + Transform Cluster Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Visualising the results \n",
    "plt.scatter(X_NMF_reduced[:,0],X_NMF_reduced[:,1],c = dataset.target)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('NMF Normal + Transform Ground Truth Label')\n",
    "plt.grid(True)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Metrics\n",
    "print('Metrics post NMF \\n')\n",
    "print(\"Homogeneity: %0.4f\" % metrics.homogeneity_score(dataset.target, vis_best_r))\n",
    "print(\"Completeness: %0.4f\" % metrics.completeness_score(dataset.target, vis_best_r))\n",
    "print(\"V-measure: %0.4f\" % metrics.v_measure_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Rand-Index: %.4f\"\n",
    "      % metrics.adjusted_rand_score(dataset.target, vis_best_r))\n",
    "print(\"Adjusted Mutual Info score: %.4f\"\n",
    "      % metrics.adjusted_mutual_info_score(dataset.target, vis_best_r))\n",
    "plt.matshow(confusion_matrix(dataset.target, vis_best_r),cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "plt.title('Contingency matrix after NMF normalization')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
